{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is meant for the students of Basics of Applied Mathematics, in the master of Mathematics in Data and Technology, Freiburg Univsersity, 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Exercise for Homework 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your task\n",
    "\n",
    "This notebook contains some code snippets with missing lines that you will have to fill in! Please also try to read and understand the parts that you do not have to fill in to understand better how the code works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A guided exercise about the Logistic regression, with gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset consists of 1797 images containing hand-written digits.\n",
    "\n",
    "Each image is with 8 x 8 pixels, and is represented as a vector $a_j \\in \\R^{64}$.\n",
    "\n",
    "Corresponding to that image, is a label $y_j \\in \\{ 0, 1, 2, ..., 9 \\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of dealing with $y_j \\in \\{0, ..., 9\\}$, we prefer replace it with vectors $p_j \\in \\R^{10}$,\n",
    "defined as follows:\n",
    "$$\n",
    "p_{j,l} = \\begin{cases} 1 & \\text{if } y_j=l \\\\   0 & \\text{if } y_j\\neq l \\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictor $\\varphi(a_j; x) \\in \\R^q$ is defined as follows:\n",
    "$$\n",
    "\\varphi(a_j; x)_i = b_i + a_j^\\top w_i\n",
    "$$\n",
    "with $x = (b_1, w_1, \\dots, b_q, w_q)$\n",
    "\n",
    "\n",
    "The goal is to have:\n",
    "$$\n",
    "\\arg \\max\\limits_{i} \\varphi(a_j; x)_i \\approx y_j\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T10:08:20.607955Z",
     "start_time": "2025-01-21T10:08:20.599852Z"
    }
   },
   "source": [
    "The probability predictor $\\hat{p}(a_j; x)$ is defined as follows:\n",
    "$$\n",
    "\\hat{p}(a_j; x) = \\text{softmax}(\\varphi(a_j; x))\n",
    "$$\n",
    "\n",
    "i.e.\n",
    "$$\n",
    "\\hat{p}(a_j; x)_i = \\frac{e^{\\varphi(a_j; x)_i}   }{ \\sum\\limits_{l=1}^q    e^{\\varphi(a_j; x)_l}  }\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the cross-entropy as follows:\n",
    "$$\n",
    "L(p_j, a_j, x) = -\\sum_{l=1}^q p_{j,l} \\log \\left(\\hat{p}(a_j; x) \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss is as follows:\n",
    "$$\n",
    "f(x) = \\frac{1}{m} \\sum_{j=1}^m L(p_j, a_j, x) \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplifications for $L$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "L(p_j, a_j, x) \n",
    "=   h(a_j, x) - \\sum_{i=1}^q p_{j,i} \\varphi(a_j; x)_i\n",
    "$$\n",
    "\n",
    "with $h(a_j, x) := \\log \\left(\\sum\\limits_{l=1}^q    e^{\\varphi(a_j; x)_l} \\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise, you will need to have scikit-learn installed on your machine.\n",
    "For that purpose, you can for example use conda:\n",
    "\n",
    "```\n",
    "    conda install scikit-learn\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T13:23:56.730206Z",
     "start_time": "2025-01-21T13:23:56.730189Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np # Package for array manipulations\n",
    "import matplotlib.pyplot as plt # Package for plotting\n",
    "from sklearn.datasets import load_digits # To load the data set\n",
    "\n",
    "# Jupyter magic command to make the plots a bit nicer\n",
    "%matplotlib notebook \n",
    "                     # replace with \"%matplotlib inline\" \n",
    "                     # in case one uses the VS code UI\n",
    "                     # instead of the Jupyter UI\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T13:23:56.734079Z",
     "start_time": "2025-01-21T13:23:56.734047Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load a data set of Digits\n",
    "digits = load_digits()\n",
    "A_tot = digits.data\n",
    "Y_tot = digits.target\n",
    "\n",
    "m_tot = Y_tot.shape[0] # number of data points\n",
    "q = 10 # q is the number of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T13:23:56.737133Z",
     "start_time": "2025-01-21T13:23:56.737107Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualize some images from the dataset\n",
    "m_example=5\n",
    "fig, axs = plt.subplots(m_example, q, figsize=(10, 10))\n",
    "\n",
    "\n",
    "for j in range(q):\n",
    "    # j is the class, gos from 0 to 9\n",
    "    data_this_label = A_tot[Y_tot==j] # all images from that class\n",
    "    for i in range(m_example): # 5 examples from this class\n",
    "        example = data_this_label[i].reshape((8,8))\n",
    "        axs[i, j].set_xticks([]) # remove ticks to make plot more pretty\n",
    "        axs[i, j].set_yticks([])\n",
    "        axs[i, j].imshow(example, cmap=plt.cm.gray)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create P "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T13:23:56.740692Z",
     "start_time": "2025-01-21T13:23:56.740661Z"
    }
   },
   "outputs": [],
   "source": [
    "P_tot = np.zeros((m_tot, q), dtype=bool)\n",
    "for l in range(q):\n",
    "    samples = (Y_tot == l)\n",
    "    P_tot[samples, l] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset in 2 parts: one for training, one for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T13:23:56.764616Z",
     "start_time": "2025-01-21T13:23:56.764587Z"
    }
   },
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(123) # random generator\n",
    "\n",
    "p_tr = 0.6 # Probability to be in the training set\n",
    "slice_tr = rng.random(m_tot) < p_tr # indices of the samples in the training dataset\n",
    "\n",
    "\n",
    "slice_test = ~slice_tr # indices of the samples in the test set\n",
    "A_tr, P_tr = A_tot[slice_tr], P_tot[slice_tr]\n",
    "A_test, P_test = A_tot[slice_test], P_tot[slice_test]\n",
    "\n",
    "m_tr = len(P_tr)\n",
    "m_test = len(P_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write some functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "   \n",
    "**Task:**\n",
    "\n",
    "Compute the number of optimization variables $n$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T13:23:56.776646Z",
     "start_time": "2025-01-21T13:23:56.776596Z"
    }
   },
   "outputs": [],
   "source": [
    "d = A_tr.shape[1]\n",
    "# ----- YOUR CODE\n",
    "n = ...\n",
    "# --------- END YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "   \n",
    "**Task:**\n",
    "\n",
    "Define the function $\\varphi(a_j, x)$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T13:23:56.784579Z",
     "start_time": "2025-01-21T13:23:56.784541Z"
    }
   },
   "outputs": [],
   "source": [
    "def phi(A, x):\n",
    "    # x is a array of size n\n",
    "    # A is an array of size m x d\n",
    "    # ----- YOUR CODE\n",
    "    phi_value = ...\n",
    "    # --------- END YOUR CODE\n",
    "    return phi_value # phi is of shape m x q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T13:23:56.792391Z",
     "start_time": "2025-01-21T13:23:56.792362Z"
    }
   },
   "outputs": [],
   "source": [
    "# This is the predictor\n",
    "def label_predictor(A, x):\n",
    "    y_pred = np.argmax(phi(A, x), axis=1)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "   \n",
    "**Task:**\n",
    "\n",
    "Define the Softmax function\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T13:23:56.795973Z",
     "start_time": "2025-01-21T13:23:56.795938Z"
    }
   },
   "outputs": [],
   "source": [
    "def softmax(arr):\n",
    "    # arr is of shape a x b\n",
    "    # ----- YOUR CODE\n",
    "    sm = ...\n",
    "    # --------- END YOUR CODE\n",
    "    return sm # shape is a x b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "   \n",
    "**Task:**\n",
    "\n",
    "Define the function H\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T13:23:56.798987Z",
     "start_time": "2025-01-21T13:23:56.798967Z"
    }
   },
   "outputs": [],
   "source": [
    "def H(A, x):\n",
    "    # ----- YOUR CODE\n",
    "    H_val = ...\n",
    "    # --------- END YOUR CODE\n",
    "    return H_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Logistic loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T13:23:56.801819Z",
     "start_time": "2025-01-21T13:23:56.801801Z"
    }
   },
   "outputs": [],
   "source": [
    "# value of the loss f(x)  (nothing to do here)\n",
    "def loss(A, P, x):\n",
    "    # P is a matrix of size m x q\n",
    "    L = H(A, x)  - np.einsum(\"mq,mq->m\", P, phi(A, x)) \n",
    "    f_value = np.mean(L)\n",
    "    return f_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the gradient "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T13:23:56.805474Z",
     "start_time": "2025-01-21T13:23:56.805454Z"
    }
   },
   "outputs": [],
   "source": [
    "# Gradient of the predictor phi (nothing to do here)\n",
    "def nabla_phi(A):\n",
    "    m = A.shape[0]\n",
    "    dphi_dX = np.zeros((m, q, (d+1), q))\n",
    "    for i in range(q):\n",
    "        dphi_dX[:, i, :-1, i] = A\n",
    "        dphi_dX[:, i, -1, i] = 1\n",
    "    dphi_dx = dphi_dX.reshape((m, q, n))\n",
    "    return dphi_dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T13:23:56.808065Z",
     "start_time": "2025-01-21T13:23:56.808034Z"
    }
   },
   "outputs": [],
   "source": [
    "# Gradient of the loss nabla f(x) (nothing to do here)\n",
    "def gradient(A, P, x, grad_phi=None):\n",
    "    if grad_phi is None:\n",
    "        # Nice to be able to precompute instead constructing the matrix at every iteration.\n",
    "        grad_phi = nabla_phi(A) # shape:  m x q x n\n",
    "\n",
    "    phi_val = phi(A, x)   # shape:  m x q\n",
    "    grad_H = np.einsum( \"mq,mqn->mn\", softmax(phi_val), grad_phi) # shape: m x n\n",
    "    grad_L = grad_H - np.einsum(\"mq,mqn->mn\", P, grad_phi)  # shape: m x n\n",
    "    grad_f = np.mean(grad_L, axis=0) # shape: n\n",
    "    return grad_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T13:23:56.811183Z",
     "start_time": "2025-01-21T13:23:56.811132Z"
    }
   },
   "outputs": [],
   "source": [
    "grad_phi_tr = nabla_phi(A_tr)\n",
    "def nabla_f(x):\n",
    "    return gradient(A_tr, P_tr, x, grad_phi=grad_phi_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "   \n",
    "**Task:**\n",
    "\n",
    "The gradient descent algorithm with a fixed step size $\\alpha$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T13:23:56.813979Z",
     "start_time": "2025-01-21T13:23:56.813927Z"
    }
   },
   "outputs": [],
   "source": [
    "def GD(x0, iter_max=100, alpha=0.1):\n",
    "    iterates = []\n",
    "    xk = x0.copy()\n",
    "    for k in range(1, iter_max):\n",
    "        # ----- YOUR CODE\n",
    "        xk = ...\n",
    "        # --------- END YOUR CODE\n",
    "        iterates.append(xk.copy())\n",
    "    return iterates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving the problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run GD with default settings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T13:23:56.816442Z",
     "start_time": "2025-01-21T13:23:56.816393Z"
    }
   },
   "outputs": [],
   "source": [
    "x0 = np.zeros(n)\n",
    "iterates = GD(x0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot value function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T13:23:56.819787Z",
     "start_time": "2025-01-21T13:23:56.819765Z"
    }
   },
   "outputs": [],
   "source": [
    "loss_training = [\n",
    "    loss(A_tr, P_tr, xk) for xk in iterates\n",
    "]\n",
    "loss_test =  [\n",
    "    loss(A_test, P_test, xk) for xk in iterates\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T13:23:56.821948Z",
     "start_time": "2025-01-21T13:23:56.821922Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel(\"Number of iteration\")\n",
    "ax.set_ylabel(\"f(x)\")\n",
    "iters = np.arange(len(iterates))\n",
    "ax.plot(iters, loss_training, \".-\", label=\"Loss on training set\")\n",
    "ax.plot(iters, loss_test, \".-\", label=\"Loss on test set\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "   \n",
    "**Task:**\n",
    "\n",
    "Comment the plot\n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions on training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T13:23:56.824430Z",
     "start_time": "2025-01-21T13:23:56.824402Z"
    }
   },
   "outputs": [],
   "source": [
    "x_sol = iterates[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T13:23:56.827808Z",
     "start_time": "2025-01-21T13:23:56.827782Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_tr = label_predictor(A_tr, x_sol)\n",
    "success_tr = P_tr[np.arange(m_tr), pred_tr]\n",
    "n_errors_tr = np.sum(~success_tr)\n",
    "print(f\"classification errors (training data) = {n_errors_tr / len(P_tr) * 100:.1f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T13:23:56.831467Z",
     "start_time": "2025-01-21T13:23:56.831439Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_test = label_predictor(A_test, x_sol)\n",
    "success_test = P_test[np.arange(m_test), pred_test]\n",
    "n_errors_test = np.sum(~success_test)\n",
    "print(f\"classification errors (test data) = {n_errors_test / len(P_test) * 100:.1f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "   \n",
    "**Task:**\n",
    "\n",
    "Comment the results\n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Visualize the solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T13:23:56.835680Z",
     "start_time": "2025-01-21T13:23:56.835646Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_examples = 10\n",
    "fig, axs = plt.subplots(1, n_examples, figsize=(15, 3))\n",
    "\n",
    "for i in range(n_examples):\n",
    "    j = np.random.randint(m_test)\n",
    "    img = A_test[j].reshape((8,8))\n",
    "    y_pred = label_predictor(A_test[j:j+1,:], x_sol).squeeze()\n",
    "    axs[i].set_xticks([])\n",
    "    axs[i].set_yticks([])\n",
    "    axs[i].imshow(img, cmap=plt.cm.gray)\n",
    "    axs[i].set_title(f\"pred={y_pred}\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different step-size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run GD with different step sizes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T13:23:56.839290Z",
     "start_time": "2025-01-21T13:23:56.839245Z"
    }
   },
   "outputs": [],
   "source": [
    "iterates_dict = {}\n",
    "for alpha in [0.2, 0.1, 0.05, 0.02]:\n",
    "    x0 = np.zeros(n)\n",
    "    iterates_dict[alpha] = GD(x0, alpha=alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot value function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T13:23:56.842887Z",
     "start_time": "2025-01-21T13:23:56.842861Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel(\"Number of iteration\")\n",
    "ax.set_ylabel(\"f(x)\")\n",
    "for alpha, it in iterates_dict.items():\n",
    "    loss_training = [ loss(A_tr, P_tr, xk) for xk in it ]\n",
    "    ax.plot(np.arange(len(it)), loss_training, \"-\", label=f\"alpha={alpha}\")\n",
    "ax.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T13:23:56.845820Z",
     "start_time": "2025-01-21T13:23:56.845794Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel(\"Number of iteration\")\n",
    "ax.set_ylabel(\"f(x)\")\n",
    "for alpha, it in iterates_dict.items():\n",
    "    loss_training = [ loss(A_tr, P_tr, xk) for xk in it ]\n",
    "    ax.plot(np.arange(len(it))[50:], loss_training[50:], \"-\", label=f\"alpha={alpha}\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "   \n",
    "**Task:**\n",
    "\n",
    "Comment the plots\n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incorporate globalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define GD with backtracking linesearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T13:23:56.849047Z",
     "start_time": "2025-01-21T13:23:56.849027Z"
    }
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return loss(A_tr, P_tr, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "   \n",
    "**Task:**\n",
    "\n",
    "Complete the following function for the backtracking line-search algorithm.\n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simplify things, instead of using the Armijo criterion, the criterion for acceptance of a step is simply to decrease the cost:\n",
    "$$\n",
    "f(x_k + \\alpha_k d_k) \\leq f(x_k)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T13:23:56.852209Z",
     "start_time": "2025-01-21T13:23:56.852184Z"
    }
   },
   "outputs": [],
   "source": [
    "def backtracking_linesearch(x, d, alpha_max=1., beta=0.9, max_iter=50):\n",
    "    alpha = alpha_max\n",
    "    for i in range(max_iter):\n",
    "        # ----- YOUR CODE\n",
    "        if ...:\n",
    "            break\n",
    "        # --------- END YOUR CODE\n",
    "        alpha = alpha * beta\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T13:23:56.855148Z",
     "start_time": "2025-01-21T13:23:56.855123Z"
    }
   },
   "outputs": [],
   "source": [
    "def GD_with_backtracking(x0, iter_max=100):\n",
    "    iterates = []\n",
    "    xk = x0.copy()\n",
    "    for k in range(1, iter_max):\n",
    "        # ----- YOUR CODE\n",
    "        xk = ...\n",
    "        # --------- END YOUR CODE\n",
    "        iterates.append(xk.copy())\n",
    "    return iterates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run GD with backtracking linesearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T13:23:56.858466Z",
     "start_time": "2025-01-21T13:23:56.858438Z"
    }
   },
   "outputs": [],
   "source": [
    "x0 = np.zeros(n)\n",
    "iterates_bt = GD_with_backtracking(x0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot value function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T13:23:56.861098Z",
     "start_time": "2025-01-21T13:23:56.861070Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel(\"Number of iteration\")\n",
    "ax.set_ylabel(\"f(x)\")\n",
    "ax.plot(np.arange(len(iterates_bt)), [f(xk) for xk in iterates_bt ], \"-\", label=\"With globalization\")\n",
    "for alpha in [0.1, 0.02]:\n",
    "    iterates_ = iterates_dict[alpha]\n",
    "    ax.plot(np.arange(len(iterates_)), [f(xk) for xk in iterates_], \"-\", label=f\"With alpha={alpha}\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T13:23:56.863920Z",
     "start_time": "2025-01-21T13:23:56.863894Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel(\"Number of iteration\")\n",
    "ax.set_ylabel(\"f(x)\")\n",
    "ax.plot(np.arange(len(iterates_bt))[50:], [f(xk) for xk in iterates_bt[50:] ], \"-\", label=\"With globalization\")\n",
    "for alpha in [0.1, 0.02]:\n",
    "    iterates_ = iterates_dict[alpha]\n",
    "    ax.plot(np.arange(len(iterates_))[50:], [f(xk) for xk in iterates_[50:] ], \"-\", label=f\"With alpha={alpha}\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "   \n",
    "**Task:**\n",
    "\n",
    "Comment the plot\n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "207px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "186.812px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
